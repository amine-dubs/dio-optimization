\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{5}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \textbf  {Cross-Domain DIO Framework:} Overview showing DIO's application across both Medical (Breast Cancer, 30D) and Vision (CIFAR-10, 2048D) domains, with nested optimization structure leading to validated results: 96.88\% accuracy (Medical) and 83.0\% accuracy (Vision). The framework demonstrates 68× dimensional scale-up validation. }}{6}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:schema1_crossdomain}{{1}{6}{\textbf {Cross-Domain DIO Framework:} Overview showing DIO's application across both Medical (Breast Cancer, 30D) and Vision (CIFAR-10, 2048D) domains, with nested optimization structure leading to validated results: 96.88\% accuracy (Medical) and 83.0\% accuracy (Vision). The framework demonstrates 68× dimensional scale-up validation}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Methodology}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Dholes-Inspired Optimization (DIO) Algorithm}{6}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}DIO Pseudocode}{8}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{lst:dio_pseudocode}{{1}{8}{Dhole-Inspired Optimization (DIO) Algorithm}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces Dhole-Inspired Optimization (DIO) Algorithm}}{8}{lstlisting.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Algorithm Validation}{9}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  extbf{DIO Algorithm Flowchart:} Complete algorithmic flow showing initialization, fitness evaluation, three hunting strategies (chase alpha, scavenge, random movement), position updates, and convergence criteria. Source: El Romeh, Snášel, Mirjalili (2025) [1]. This flowchart illustrates the core mechanism adapted in our Python implementation for machine learning optimization. }}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:dio_flowchart}{{2}{10}{extbf{DIO Algorithm Flowchart:} Complete algorithmic flow showing initialization, fitness evaluation, three hunting strategies (chase alpha, scavenge, random movement), position updates, and convergence criteria. Source: El Romeh, Snášel, Mirjalili (2025) [1]. This flowchart illustrates the core mechanism adapted in our Python implementation for machine learning optimization}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Benchmark Comparison with Other Metaheuristics}{10}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  extbf{DIO Performance on Engineering Benchmark:} Comparison of DIO with state-of-the-art metaheuristic algorithms (Genetic Algorithm, Particle Swarm Optimization, Differential Evolution, Grey Wolf Optimizer, Whale Optimization Algorithm, and others) on the Pressure Vessel Design Problem. DIO demonstrates competitive performance with best/mean/worst cost values comparable to or better than established methods. Source: El Romeh, Snášel, Mirjalili (2025) [1]. This benchmark validation supports our selection of DIO for machine learning hyperparameter optimization tasks. }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:dio_comparison}{{3}{11}{extbf{DIO Performance on Engineering Benchmark:} Comparison of DIO with state-of-the-art metaheuristic algorithms (Genetic Algorithm, Particle Swarm Optimization, Differential Evolution, Grey Wolf Optimizer, Whale Optimization Algorithm, and others) on the Pressure Vessel Design Problem. DIO demonstrates competitive performance with best/mean/worst cost values comparable to or better than established methods. Source: El Romeh, Snášel, Mirjalili (2025) [1]. This benchmark validation supports our selection of DIO for machine learning hyperparameter optimization tasks}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Random Forest Architecture}{11}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}XGBoost Architecture}{12}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Modeling DIO: From MATLAB to Python}{12}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \textbf  {DIO Python Implementation:} Core optimization loop showing population initialization, fitness evaluation, and iterative position updates using the three hunting strategies. This modular design enables seamless integration with scikit-learn and XGBoost classifiers. }}{13}{figure.caption.5}\protected@file@percent }
\newlabel{fig:dio_snippet}{{4}{13}{\textbf {DIO Python Implementation:} Core optimization loop showing population initialization, fitness evaluation, and iterative position updates using the three hunting strategies. This modular design enables seamless integration with scikit-learn and XGBoost classifiers}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Optimization Framework}{14}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Nested Optimization Structure}{14}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \textbf  {Nested Optimization Architecture:} Hierarchical structure showing the Outer Loop (hyperparameter optimization) containing the Inner Loop (feature selection). Each outer iteration evaluates hyperparameters $\theta $ while the inner loop finds optimal features S* for that $\theta $. Medical: 50×50=2,500 evaluations (54 sec). Vision: 24×24=576 evaluations (5.4 hrs). }}{15}{figure.caption.6}\protected@file@percent }
\newlabel{fig:schema4_nested}{{5}{15}{\textbf {Nested Optimization Architecture:} Hierarchical structure showing the Outer Loop (hyperparameter optimization) containing the Inner Loop (feature selection). Each outer iteration evaluates hyperparameters $\theta $ while the inner loop finds optimal features S* for that $\theta $. Medical: 50×50=2,500 evaluations (54 sec). Vision: 24×24=576 evaluations (5.4 hrs)}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Fitness Function}{15}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  \textbf  {Modularization \& Fitness Function:} The complete optimization mechanism showing how fitness F drives both nested loops. The outer loop tests hyperparameters $\theta $ while the inner loop (for each $\theta $) finds optimal features S*. Both minimize F = 0.99×(1-Acc) + 0.01×(Feat/Total). Total evaluations = Outer\_iterations × Inner\_iterations. This is the core technical schema explaining HOW the optimization works. }}{16}{figure.caption.7}\protected@file@percent }
\newlabel{fig:schema5_modularization}{{6}{16}{\textbf {Modularization \& Fitness Function:} The complete optimization mechanism showing how fitness F drives both nested loops. The outer loop tests hyperparameters $\theta $ while the inner loop (for each $\theta $) finds optimal features S*. Both minimize F = 0.99×(1-Acc) + 0.01×(Feat/Total). Total evaluations = Outer\_iterations × Inner\_iterations. This is the core technical schema explaining HOW the optimization works}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  \textbf  {Feature Selection Objective Function:} Python implementation of the inner loop fitness function. For each feature subset (binary mask), the function trains a Random Forest with given hyperparameters and evaluates accuracy via cross-validation. Returns fitness = 0.99×(1-CV\_accuracy) + 0.01×(feature\_ratio) to be minimized. }}{17}{figure.caption.8}\protected@file@percent }
\newlabel{fig:feature_selection_obj}{{7}{17}{\textbf {Feature Selection Objective Function:} Python implementation of the inner loop fitness function. For each feature subset (binary mask), the function trains a Random Forest with given hyperparameters and evaluates accuracy via cross-validation. Returns fitness = 0.99×(1-CV\_accuracy) + 0.01×(feature\_ratio) to be minimized}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  \textbf  {Hyperparameter Objective Function:} Outer loop fitness function that receives hyperparameters, launches inner DIO for feature selection, and returns the best fitness from optimizing features with those hyperparameters. This creates the nested optimization hierarchy. }}{18}{figure.caption.9}\protected@file@percent }
\newlabel{fig:hyperparameter_obj}{{8}{18}{\textbf {Hyperparameter Objective Function:} Outer loop fitness function that receives hyperparameters, launches inner DIO for feature selection, and returns the best fitness from optimizing features with those hyperparameters. This creates the nested optimization hierarchy}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Experimental Setup}{18}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Dataset Selection and Characteristics}{18}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}DIO Configuration}{19}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  \textbf  {Outer Loop Execution and Results Retrieval:} Code showing how the outer DIO is launched with hyperparameter bounds, how it calls the inner loop for feature selection, and how final optimized hyperparameters and features are extracted after convergence. Demonstrates end-to-end optimization workflow. }}{20}{figure.caption.10}\protected@file@percent }
\newlabel{fig:outer_optimization}{{9}{20}{\textbf {Outer Loop Execution and Results Retrieval:} Code showing how the outer DIO is launched with hyperparameter bounds, how it calls the inner loop for feature selection, and how final optimized hyperparameters and features are extracted after convergence. Demonstrates end-to-end optimization workflow}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Validation Strategy}{20}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Baseline Models}{21}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.5}Statistical Analysis}{21}{subsubsection.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.6}Performance Metrics}{22}{subsubsection.3.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Optional Note: Hyper-Heuristics}{22}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussion}{22}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overall Model Performance}{22}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Model Performance Summary over 30 Runs (Top 5 and DIO)}}{22}{table.caption.11}\protected@file@percent }
\newlabel{tab:model_summary}{{1}{22}{Model Performance Summary over 30 Runs (Top 5 and DIO)}{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Statistical Significance}{23}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Wilcoxon Signed-Rank Test p-values (DIO-Optimized RF vs. Other Models)}}{23}{table.caption.12}\protected@file@percent }
\newlabel{tab:wilcoxon}{{2}{23}{Wilcoxon Signed-Rank Test p-values (DIO-Optimized RF vs. Other Models)}{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Visual Analysis}{23}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Six-panel comparison of all 10 models across 30 runs for single-split optimization approach.}}{24}{figure.caption.13}\protected@file@percent }
\newlabel{fig:main_viz}{{10}{24}{Six-panel comparison of all 10 models across 30 runs for single-split optimization approach}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Pareto-Optimal Solution}{24}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Feature Selection Analysis}{24}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Detailed Performance Comparison}{25}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Optimization Overfitting: A Critical Insight}{25}{subsection.4.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \textbf  {Single Run Optimization Results:} DIO-Optimized RF achieved 99\% accuracy (rank \#1) on the single optimization split. However, this impressive single-run performance masked severe overfitting—when validated across 30 different data splits, the same configuration dropped to 94.37\% (rank \#6). This stark degradation (from \#1 to \#6) demonstrates that hyperparameters can memorize quirks of a specific train/test partition rather than learning generalizable patterns.}}{26}{figure.caption.14}\protected@file@percent }
\newlabel{fig:single_run_overfitting}{{11}{26}{\textbf {Single Run Optimization Results:} DIO-Optimized RF achieved 99\% accuracy (rank \#1) on the single optimization split. However, this impressive single-run performance masked severe overfitting—when validated across 30 different data splits, the same configuration dropped to 94.37\% (rank \#6). This stark degradation (from \#1 to \#6) demonstrates that hyperparameters can memorize quirks of a specific train/test partition rather than learning generalizable patterns}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  \textbf  {Optimization Overfitting Discovery:} Comparison of three approaches showing algorithm-dependent behavior. RF Single-Split achieved 99\% in optimization but only 94.37\% validation (rank \#6) - clear overfitting from rank \#1 to \#6. RF-CV fixed this (96.55\%, rank \#1) but took 7.9 hours. XGBoost Single-Split achieved best results (96.88\%, rank \#1) in only 54 seconds, proving gradient boosting's built-in regularization prevents meta-overfitting. KEY FINDING: Algorithm choice determines if CV is necessary. }}{27}{figure.caption.15}\protected@file@percent }
\newlabel{fig:schema2_overfitting}{{12}{27}{\textbf {Optimization Overfitting Discovery:} Comparison of three approaches showing algorithm-dependent behavior. RF Single-Split achieved 99\% in optimization but only 94.37\% validation (rank \#6) - clear overfitting from rank \#1 to \#6. RF-CV fixed this (96.55\%, rank \#1) but took 7.9 hours. XGBoost Single-Split achieved best results (96.88\%, rank \#1) in only 54 seconds, proving gradient boosting's built-in regularization prevents meta-overfitting. KEY FINDING: Algorithm choice determines if CV is necessary}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}The Phenomenon}{27}{subsubsection.4.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}Why This Matters}{27}{subsubsection.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.3}Recommended Approach}{28}{subsubsection.4.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}CV-Based Optimization: Validating the Solution}{28}{subsection.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.1}CV-Optimized Configuration}{28}{subsubsection.4.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces CV-based optimization convergence and model comparison visualization showing the optimization process across iterations.}}{29}{figure.caption.16}\protected@file@percent }
\newlabel{fig:cv_opt_viz}{{13}{29}{CV-based optimization convergence and model comparison visualization showing the optimization process across iterations}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.2}30-Run Statistical Validation}{29}{subsubsection.4.8.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces CV-Optimized Model Performance Summary (30 Runs)}}{29}{table.caption.17}\protected@file@percent }
\newlabel{tab:cv_results}{{3}{29}{CV-Optimized Model Performance Summary (30 Runs)}{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Six-panel comparison of CV-optimized model across 30 runs, showing improved stability and generalization.}}{30}{figure.caption.18}\protected@file@percent }
\newlabel{fig:cv_viz}{{14}{30}{Six-panel comparison of CV-optimized model across 30 runs, showing improved stability and generalization}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Individual model performance trends across 30 independent runs for CV-optimized configuration. Each subplot shows accuracy (solid) and F1-score (dashed) trajectories, with red horizontal lines indicating mean accuracy.}}{30}{figure.caption.19}\protected@file@percent }
\newlabel{fig:cv_trends}{{15}{30}{Individual model performance trends across 30 independent runs for CV-optimized configuration. Each subplot shows accuracy (solid) and F1-score (dashed) trajectories, with red horizontal lines indicating mean accuracy}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces ROC curves for CV-optimized model showing excellent discrimination capability with AUC near 1.0, demonstrating strong classification performance on both classes.}}{31}{figure.caption.20}\protected@file@percent }
\newlabel{fig:cv_roc}{{16}{31}{ROC curves for CV-optimized model showing excellent discrimination capability with AUC near 1.0, demonstrating strong classification performance on both classes}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.3}Statistical Significance Analysis}{31}{subsubsection.4.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A Remaining Question}{32}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.4}Comparison: Single-Split vs. CV-Based}{32}{subsubsection.4.8.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Single-Split vs. CV-Based Optimization Comparison}}{32}{table.caption.22}\protected@file@percent }
\newlabel{tab:comparison}{{4}{32}{Single-Split vs. CV-Based Optimization Comparison}{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.5}Key Insights}{32}{subsubsection.4.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Robustness and Generalization}{33}{subsection.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}XGBoost Optimization: Exploring Gradient Boosting}{33}{subsection.4.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.10.1}XGBoost-Optimized Configuration}{33}{subsubsection.4.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces  \textbf  {XGBoost Hyperparameter Search Space (Medical Domain):} Configuration showing the 5-dimensional search space for breast cancer classification: n\_estimators [10-200], max\_depth [1-20], learning\_rate [0.01-0.3], subsample [0.5-1.0], colsample\_bytree [0.5-1.0]. DIO simultaneously optimizes these parameters with feature selection in the nested framework. }}{34}{figure.caption.23}\protected@file@percent }
\newlabel{fig:xgb_search_space_cancer}{{17}{34}{\textbf {XGBoost Hyperparameter Search Space (Medical Domain):} Configuration showing the 5-dimensional search space for breast cancer classification: n\_estimators [10-200], max\_depth [1-20], learning\_rate [0.01-0.3], subsample [0.5-1.0], colsample\_bytree [0.5-1.0]. DIO simultaneously optimizes these parameters with feature selection in the nested framework}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces XGBoost optimization convergence visualization showing fitness evolution and final model performance across the nested DIO optimization process.}}{35}{figure.caption.24}\protected@file@percent }
\newlabel{fig:xgb_opt_viz}{{18}{35}{XGBoost optimization convergence visualization showing fitness evolution and final model performance across the nested DIO optimization process}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.10.2}30-Run Statistical Validation}{35}{subsubsection.4.10.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces XGBoost-Optimized Model Performance Summary (30 Runs)}}{35}{table.caption.25}\protected@file@percent }
\newlabel{tab:xgb_results}{{5}{35}{XGBoost-Optimized Model Performance Summary (30 Runs)}{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Six-panel comparison of XGBoost-optimized model across 30 runs, showing superior performance and stability.}}{36}{figure.caption.26}\protected@file@percent }
\newlabel{fig:xgb_viz}{{19}{36}{Six-panel comparison of XGBoost-optimized model across 30 runs, showing superior performance and stability}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.10.3}Statistical Significance Analysis}{36}{subsubsection.4.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.10.4}Comparison: XGBoost vs. Random Forest Optimization}{37}{subsubsection.4.10.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces XGBoost vs. Random Forest DIO Optimization Comparison}}{37}{table.caption.27}\protected@file@percent }
\newlabel{tab:xgb_rf_comparison}{{6}{37}{XGBoost vs. Random Forest DIO Optimization Comparison}{table.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.10.5}Clinical Deployment Recommendation}{37}{subsubsection.4.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.11}Robustness and Generalization}{38}{subsection.4.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12}Clinical Deployment Recommendations}{38}{subsection.4.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13}Comparison with Hyper-Heuristic Approach}{39}{subsection.4.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14}Limitations}{39}{subsection.4.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.15}Future Work}{40}{subsection.4.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Extension to Image Classification: CIFAR-10 Deep Learning Features}{41}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Motivation for Dataset Extension}{41}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Dataset and Feature Extraction}{42}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Model Selection: Comparison Phase}{42}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces CIFAR-10 Model Comparison Results (Full Dataset)}}{43}{table.caption.28}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces CIFAR-10 Sample Images: Representative examples from the 10 classes (automobile, frog, ship, deer, dog, bird, airplane, cat) used in the image classification experiments with ResNet50 features.}}{43}{figure.caption.29}\protected@file@percent }
\newlabel{fig:cifar10_samples}{{20}{43}{CIFAR-10 Sample Images: Representative examples from the 10 classes (automobile, frog, ship, deer, dog, bird, airplane, cat) used in the image classification experiments with ResNet50 features}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Test Accuracy Comparison: XGBoost (85.0\%), Gradient Boosting (82.0\%), and Random Forest (83.0\%) on CIFAR-10 with ResNet50 features.}}{43}{figure.caption.30}\protected@file@percent }
\newlabel{fig:test_accuracy}{{21}{43}{Test Accuracy Comparison: XGBoost (85.0\%), Gradient Boosting (82.0\%), and Random Forest (83.0\%) on CIFAR-10 with ResNet50 features}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}DIO Optimization Configuration}{44}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  \textbf  {XGBoost Hyperparameter Search Space (Vision Domain):} Configuration for CIFAR-10 image classification showing the 3-dimensional search space: n\_estimators [30-100], max\_depth [3-10], learning\_rate [0.01-0.3]. Reduced search space compared to medical domain due to computational constraints of 2048-D feature space. }}{45}{figure.caption.31}\protected@file@percent }
\newlabel{fig:xgb_search_space_images}{{22}{45}{\textbf {XGBoost Hyperparameter Search Space (Vision Domain):} Configuration for CIFAR-10 image classification showing the 3-dimensional search space: n\_estimators [30-100], max\_depth [3-10], learning\_rate [0.01-0.3]. Reduced search space compared to medical domain due to computational constraints of 2048-D feature space}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Optimization Results}{45}{subsection.5.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces DIO-Optimized XGBoost for CIFAR-10 (Subset: 2K Train, 500 Test)}}{46}{table.caption.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Visualization and Interpretation}{47}{subsection.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces DIO-Optimized XGBoost Performance on CIFAR-10 Subset: (Left) Test accuracy comparison showing 2.2\% improvement over baseline (83.0\% vs 80.8\%). (Right) Feature count reduction from 2,048 to 598 features (70.8\% reduction) while achieving superior accuracy.}}{47}{figure.caption.33}\protected@file@percent }
\newlabel{fig:cifar10_results}{{23}{47}{DIO-Optimized XGBoost Performance on CIFAR-10 Subset: (Left) Test accuracy comparison showing 2.2\% improvement over baseline (83.0\% vs 80.8\%). (Right) Feature count reduction from 2,048 to 598 features (70.8\% reduction) while achieving superior accuracy}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Statistical Validation: 30-Run Comparison}{48}{subsection.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.7.1}Experimental Setup}{48}{subsubsection.5.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.7.2}Results: Optimization Overfitting Revealed}{48}{subsubsection.5.7.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Statistical Comparison of CIFAR-10 Models (30 Runs)}}{48}{table.caption.34}\protected@file@percent }
\newlabel{tab:cifar_stats}{{9}{48}{Statistical Comparison of CIFAR-10 Models (30 Runs)}{table.caption.34}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Wilcoxon Signed-Rank Test: DIO-XGBoost vs. Baselines (CIFAR-10)}}{48}{table.caption.35}\protected@file@percent }
\newlabel{tab:cifar_wilcoxon}{{10}{48}{Wilcoxon Signed-Rank Test: DIO-XGBoost vs. Baselines (CIFAR-10)}{table.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Statistical Comparison of CIFAR-10 Models Across 30 Runs: (Left) Accuracy distribution boxplots showing XGBoost Default (All features) as the clear winner. (Right) Mean accuracy with standard deviation, revealing that DIO-optimized configuration ranks 3rd, significantly underperforming default XGBoost (p$<$0.0001).}}{49}{figure.caption.36}\protected@file@percent }
\newlabel{fig:cifar_stats}{{24}{49}{Statistical Comparison of CIFAR-10 Models Across 30 Runs: (Left) Accuracy distribution boxplots showing XGBoost Default (All features) as the clear winner. (Right) Mean accuracy with standard deviation, revealing that DIO-optimized configuration ranks 3rd, significantly underperforming default XGBoost (p$<$0.0001)}{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.7.3}Critical Findings: Optimization Overfitting in High Dimensions}{49}{subsubsection.5.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Comparative Analysis: Medical vs. Image Data}{50}{subsection.5.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces DIO Performance Across Domains (Statistical Validation)}}{50}{table.caption.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Real-World Applications for Vision Tasks}{51}{subsection.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10}Limitations and Future Work}{52}{subsection.5.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11}Summary of Image Classification Extension}{53}{subsection.5.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{53}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Summary of Contributions}{53}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Key Findings Across Domains}{56}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces  \textbf  {Three-Approach Research Progression:} Timeline showing evolution from RF Single-Split (discovered overfitting, 1 min, 94.37\%, rank \#6) → RF-CV (fixed overfitting, 7.9 hrs, 96.55\%, rank \#1) → XGBoost (best solution, 54 sec, 96.88\%, rank \#1). Key insight: Both RF-CV and XGBoost achieve top accuracy, but XGBoost requires 870× less time due to built-in regularization. Trade-off between feature interpretability (6 vs 10 features) and computational efficiency. }}{56}{figure.caption.38}\protected@file@percent }
\newlabel{fig:schema6_evolution}{{25}{56}{\textbf {Three-Approach Research Progression:} Timeline showing evolution from RF Single-Split (discovered overfitting, 1 min, 94.37\%, rank \#6) → RF-CV (fixed overfitting, 7.9 hrs, 96.55\%, rank \#1) → XGBoost (best solution, 54 sec, 96.88\%, rank \#1). Key insight: Both RF-CV and XGBoost achieve top accuracy, but XGBoost requires 870× less time due to built-in regularization. Trade-off between feature interpretability (6 vs 10 features) and computational efficiency}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces  \textbf  {Cross-Domain Results Comparison:} Quantitative comparison showing DIO's effectiveness across Medical (30D, binary classification, 455 samples) and Vision (2048D, 10-class, 2000 samples) domains. Medical: 96.88\% accuracy (best result), 67\% feature reduction, 54 sec optimization. Vision: 83.0\% accuracy (+2.2\% gain), 70.8\% feature reduction, 5.4 hrs optimization. Validates 68× dimensional scale-up. Both domains show consistent pattern: accuracy improvement + substantial feature reduction. }}{58}{figure.caption.39}\protected@file@percent }
\newlabel{fig:schema3_comparison}{{26}{58}{\textbf {Cross-Domain Results Comparison:} Quantitative comparison showing DIO's effectiveness across Medical (30D, binary classification, 455 samples) and Vision (2048D, 10-class, 2000 samples) domains. Medical: 96.88\% accuracy (best result), 67\% feature reduction, 54 sec optimization. Vision: 83.0\% accuracy (+2.2\% gain), 70.8\% feature reduction, 5.4 hrs optimization. Validates 68× dimensional scale-up. Both domains show consistent pattern: accuracy improvement + substantial feature reduction}{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Practical Impact Across Domains}{58}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Broader Implications}{59}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Final Remarks}{60}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Acknowledgments}{61}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{61}{section*.41}\protected@file@percent }
\gdef \@abspage@last{62}
